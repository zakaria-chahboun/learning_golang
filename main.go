package main

import (
	"context"
	"fmt"
	"io"
	"log"
	"net/http"
	"sort"
	"sync"
	"sync/atomic"
	"time"

	"example.com/bill"
)

func main() {
	// playing with strcuts and their functions
	// example1()

	// playign with arrays & slices
	// example2()

	// playing with interfaces
	// example3()

	// playing with maps
	// example4()

	// playing with concurency
	// example5()

	// implementation of setTimeout (js)
	// ---- Way 1 ----
	// setTimeout1()
	// ---- Way 2 ----
	// setTimeout2()

	// Go Tickers: implementation of setInterval (js) + (Sleep Vs Ticker)
	//example6()

	// playing with context
	// example7()

	// playing with context (advanced) start the server fisrt (look inside it)
	//example8()

	// playing with the singleton pattern
	// example9()

	// playing with Atomic Counters
	// example10()

	// playing with mutex
	// example11()

	// playing with sort package
	example12()
}

// --------------------------- //
func example1() {

	perfum := bill.Product{ID: 1, Title: "Raghba Lattafa", Price: 120.00}
	invoice := bill.Invoice{ID: 1, Product: perfum, Date: time.Now()}
	fmt.Println(invoice)
	fmt.Println(invoice.IsOutdated())
	invoice.Date = invoice.Date.Add(time.Hour * 24 * 7)
	fmt.Println(invoice)
	fmt.Println(invoice.IsOutdated())
}

// --------------------------- //
func example2() {
	array := [3]int{1, 2, 3}       // this is an array with length = 3
	array1 := [...]int{1, 2, 3, 4} // this is an array with length = 4 generated by the compiler
	slice := array[1:2]            // this i a slice of array, [index, index not included]
	slice1 := []int{1, 2, 3, 4, 5} // this is a slice! the compiler create an array then return a slice
	fmt.Println("array:", array, "array1:", array1, "slice:", slice, "slice1:", slice1)
	/*
		The length of an array is matter: "array != array1"
		The function "readSlice(..)" accept only a slice not an array!
			but you can pass the array to it as a slice: "array[:]"
	*/
	readSlice(slice1)
	readSlice(array[:])
	fmt.Println("length of array:", len(array))
	fmt.Println("capacity of array:", cap(array)) // cap is how mush free space?

	// -- Dynamic Arrays --
	var table = make([]int, 3) // (array type, init capatity or size)
	table[0] = 5
	table[1] = 6
	table[2] = 7
	/*
		If we want to add table[3] we have to expand the array by "append(..)" function
	*/
	table = append(table, 8) // (table, the element to add)
	fmt.Println("dynamic table", table)
}

func readSlice(s []int) {
	// visit the example12()

	fmt.Println("readSlice:")
	for _, v := range s {
		fmt.Println(v)
	}
}

// --------------------------- //
func example3() {
	jamal := Freelancer{ID: 1, workingHours: 75, pricePeerHour: 100}
	amal := Salary{ID: 2, monthlyPrice: 3500, months: 2, bonus: 100}
	total := totalExpense([]Worker{jamal, amal})
	fmt.Println("Total Expense:", total)

	// trying the empty interface
	anything(45)
	anything("hello")
	anything([]int{1, 2, 3})
}

type Worker interface {
	CalculateSalary() float64
}
type Freelancer struct {
	ID            int
	workingHours  float64
	pricePeerHour float64
}
type Salary struct {
	ID           int
	monthlyPrice float64
	months       int
	bonus        int
}

// The "Freelancer" implements the "Worker" interface
func (this Freelancer) CalculateSalary() float64 {
	return this.pricePeerHour * this.workingHours
}

// The "Salary" implements the "Woker" interface
func (this Salary) CalculateSalary() float64 {
	return (this.monthlyPrice * float64(this.months)) + float64(this.bonus)
}

// Becuase "Freelancer" and "Salary" are both "Worker"s
func totalExpense(w []Worker) float64 {
	var total float64 = 0
	for _, v := range w {
		total += v.CalculateSalary()
	}
	return total
}

// empty interface is like the "any" type of Typecript!
func anything(t interface{}) {
	fmt.Printf("my value: %v, my type: %T\n", t, t)
}

// --------------------------- //
func example4() {
	results := map[string]int{} // [key]value
	results["kamal"] = 12
	results["said"] = 15
	results["mohsin"] = 13
	fmt.Println("results:", results)
	// to delete a value in map
	delete(results, "kamal")
	fmt.Println("results:", results)
	// kamal now is deleted but if we call it it give us a "0" value, cuze of go initialization
	fmt.Println("kamal value after deleting:", results["kamal"])
	// how we can make the deference between "0" of null and the real "0"?
	// the map return two things, "value, existing"
	value, ok := results["kamal"]
	fmt.Println("kamal value:", value, ",but is kanmal exist?", ok)
	fmt.Println("how many results there?", len(results))

	// trying anonymous function
	isExist := func(m map[string]int, key string) string {
		_, ok := m[key]
		if ok {
			return "yes"
		}
		return "no"
	}
	fmt.Println("kamal value:", value, ",but is kanmal exist?", isExist(results, "kamal"))
}

// --------------------------- //
func example5() {
	// ---- First way ----

	// Desctiption: now both of the process 'A'&'B' run in the same time concurentlry

	var wg sync.WaitGroup // think of it as a counter
	wg.Add(2)             // how many go routines we have? in this example (2 go functions)

	// async anonymous function run immediately
	go func() {
		process("A") // run process "A"
		wg.Done()    // emit the 'done' signal after finishing the process 'A'
	}()

	go func() {
		process("B")
		wg.Done()
	}()

	wg.Wait() // important for wating for the go routines: (blocks code here until all go routines above are finished)

	// ---- Second way ---- (communicate with process using channels)
	/*
	   - A Go channel is a communication mechanism that allows Goroutines to exchange data.
	   When developers have numerous Goroutines running at the same time,
	   channels are the most convenient way to communicate with each other.
	   - Developers often use these channels for notifications and managing concurrency in applications.
	*/

	out := make(chan string) // create a unbaffred channel
	go process1("C", out)

	out1 := <-out // the code is blocked until someone write into the pipe :) (this is the job of the process1 func)
	println("Receiver side x:", out1)

	// the 'go function' and the 'for loop', runs in concurently
	// the 'range chan', is reading from the channel until it closed!
	for msg := range out {
		println("Receiver side:", msg)
	}

	// ----- Third way ----- (baffred channels)
	/*
		the unbaffred channels blocks until some 'Go routines' read or write to it
		but we can avoid that by creating a `buffred channles` with a `capacity`!
	*/
	cha := make(chan int, 1) // buffred channel with the capatity of 1, that's means we can write&read from it (1 time) without a go routine!

	cha <- 5
	data, open := <-cha
	fmt.Println(data, open) // '5 true' why? 'true' means is open
	//data, open = <-cha // error? cuz we have only capacity == 1, so to avoid that increase the capacity or write to the channel again, it's a read write sequence

	cha <- 42
	data = <-cha
	close(cha)
	_, open = <-cha
	fmt.Println(data, open) // 42 false

}

func process(name string) {
	for i := 1; i <= 5; i++ {
		println(name, i)
		time.Sleep(time.Second)
	}
}
func process1(name string, out chan string) {
	for i := 1; i <= 5; i++ {
		out <- fmt.Sprint(name, i)
		time.Sleep(time.Second)
	}
	println("-- process1 end --")
	close(out) // manually close channel, never doing that in the receiver side!
	/*
		- cuz if we send data to a closed channel, the runtime crashed!
		- to avoid blocking, always close channel after the writing process
		- if we didn't that we got this error message:
		"fatal error: all goroutines are asleep - deadlock!"
	*/
	//	defer close(out)
	/*
		[ defer = fach tssali ]
			we can do that instead of closing manually the channel
			the 'defer' run the code after the end of the scope!
			so you can put it in the top if you want!
	*/
}

// --------------------------- //
func setTimeout1() {
	// set a duration
	duration := time.Duration(time.Second * 2)

	// we have just 1 timeout function (a.k.a go routines)
	var wg sync.WaitGroup
	wg.Add(1)

	// our anonymous setTimeout function
	go func() {
		defer wg.Done() // will work in any case, even if the func broken
		time.Sleep(duration)
		fmt.Println("i'm runing after ", duration)
	}()

	// ---- Our main code here ----
	println("---- I don't wait ----")

	// block the main until our (go routines) finished
	wg.Wait()
}
func setTimeout2() {
	// to let the "main" wating for us
	done := make(chan int)
	// block or wait for our setTimeout
	defer func() { <-done }()

	// setTimeout :) after 3 secs
	time.AfterFunc(time.Second*3, func() {
		fmt.Println("i'm running after 3 s")
		done <- 0 // finish or exit
	})

	// ---- Our main code here ----
	println("---- I don't wait ----")
}

// --------------------------- //
func example6() {
	/*
		Tickers are for when you want to do something repeatedly at regular intervals
	*/

	// ticker with Every 1 secs
	tk := time.NewTicker(time.Second)

	fmt.Println("Start..")

	// loop over "tk.C" channel, until "tk.Stop()"
	counter := 1
	for range tk.C {
		log.Println("Calling", counter)

		// stop after 4 iteration
		if counter == 4 {
			tk.Stop()
			break
		}
		counter++
	}

	/*
		of course if you want a non-blocking alternative to setInterval of js
		you have to work with tickers + go routines
		----------------
		Sleep Vs Ticker
		----------------
		- time.Sleep just waits for the provided time and continues with the program. There is no adjustment if the rest of the code takes longer.

		- The ticker takes the execution time of the provided block into account and skips an interval, if necessary.

		Imagine this scenario: You provide an interval of one minute and your code takes 10 seconds to execute.

		- In your first version your program executes your code for ten seconds and then sleeps for 60 seconds. Practically it gets called every 70 seconds.

		- In your second version your code gets executed for 10 seconds, then the ticker adjusts the wait time to 50 seconds. Your code gets executed exactly each minute.
	*/
}

// --------------------------- //
func example7() {

	/*
		We can use context as a store (like context in svelte)
		The context store the data in a "map", so yu can use what ever type of data!
	*/
	myStore := context.Background() // scoped context: means my parent is "this" func: example7()
	myStore = storeValue(myStore)   // return a new store (immutable)
	readValue(myStore)

	storeValue2(&myStore) // mutable store
	readValue(myStore)

	/*
		we can also make a deadline or timeout to our functions that subscibe to the context
		by calling "cancel()" manually or by a duration
	*/
	parent := context.Background()                            // like "this" in other langs
	ctx, cancel := context.WithTimeout(parent, time.Second*3) // rule: after 3 secs, cancel the job
	defer cancel()                                            // don't forget this, cuz the timer is eating some resources if the main is done before the time is done

	// our func is subscribed to the context, so
	// the context terminate in a 3 secs, the job is cancelled!
	sleepAndTalk(ctx)

	/*
		- Why we need the context? we can do that by just a normal timer!
		the answer is, Nope!

		- The power of the context is, if any reason the "root or parent" context gets cancelled
		that cancellation will propagate to all the children contexts
		and all of those operations will stop!
	*/
}

func storeValue(ctx context.Context) context.Context {
	// context, key, value!
	newContext := context.WithValue(ctx, "name", "zaki")
	return newContext
	/*
		store the "key,value" in the "context"
	*/
}
func storeValue2(ctx *context.Context) {
	// edit the current context! pointer
	*ctx = context.WithValue(*ctx, "name", "karim")
}
func readValue(ctx context.Context) {
	// retrieve the key "name"
	val := ctx.Value("name")
	fmt.Println(val)
}
func sleepAndTalk(ctx context.Context) {
	// sleep a 5 sec then talk, but if the context is canceled, then print an error
	// it's a deadline bro!

	select {
	case <-time.After(time.Second * 5):
		fmt.Println("i'm talking after 5 secs")
	case <-ctx.Done():
		println(ctx.Err().Error())
	}
}

// --------------------------- //
func example8() {
	/*
		- Note:
			You have to start the server by:
			go run server/server.go

			You can use the browser or the "client1()" func!
	*/

	fmt.Println("loading ...")
	// trying a normal http call to the server
	//client1()

	/*
	 Calling the request with a context
	 The client abort the connection after 3 secs (timeout),
	 So the server now reveive this signal and save some resources! Cool!
	*/
	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		// this will aborted afer 3 secs
		client2("http://localhost:8080", time.Second*2)
		wg.Done()
	}()

	wg.Add(1)
	func() {
		// this will recieve the "Hello Go! [2]" body msg, cuz the time out is too big!
		client2("http://localhost:8080/2", time.Second*7)
		wg.Done()
	}()
	wg.Wait()
}

func client1() {
	// call the server
	res, err := http.Get("http://localhost:8080")

	// error handling
	if err != nil {
		log.Fatal(err.Error())
	}
	if res.StatusCode != http.StatusOK {
		log.Fatal(res.Status)
	}
	// important
	defer res.Body.Close()

	// just print what the server gives us! :)
	bytes, _ := io.ReadAll(res.Body)
	fmt.Println("Client received: ", string(bytes))
}

func client2(url string, timeout time.Duration) {
	/*
		Like the client1() func, but this time we add a timeout to the context in the request
		So with that, We have to separate the request and the responce funcs

		Now the request context has two things:
		(1) the abort calling (by user hand) "the default req context"
		(2) + our new rule: the time out!
		Cool!, we don't mess with the server or the handlers,
		We just did that here by the context inheritence!
	*/

	ctx := context.Background()
	// abort the request if we passed 3 secs
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	// create a new request with our context
	req, err := http.NewRequestWithContext(ctx, http.MethodGet, url, nil)

	// error handling
	if err != nil {
		fmt.Println(err.Error())
		return
	}

	// make the call of the request
	res, err := http.DefaultClient.Do(req)

	// error handling
	if err != nil {
		fmt.Println(err.Error())
		return
	}
	if res.StatusCode != http.StatusOK {
		fmt.Println(res.Status)
		return
	}
	// important
	defer res.Body.Close()

	// just print what the server gives us! :)
	bytes, _ := io.ReadAll(res.Body)
	fmt.Println("Client received: ", string(bytes))
}

// --------------------------- //
func example9() {
	/*
		The singleton pattern:
		Sometimes we need our code to be executed only once in the entire lifetime!
		So we can do this with mutext.lock/unlock, but to be more crleary and 100% safe
		We use the "Sync" package with the "..Do()" funtion!
	*/

	var Once sync.Once

	// Here is a sample program that shows how even if you call it multiple times, it gets executed only once.
	for range []int{1, 2, 3} {
		Once.Do(func() {
			fmt.Println("I executed jut once!")
		})
	}

	/*
		The "singleton pattern" is useful when
			we one to instantiate a database connection one time
			even if our app is calling the constractor function many times!
	*/
}

// --------------------------- //
func example10() {

	/*
		Here we’ll look at using the sync/atomic package for atomic counters
		accessed by multiple goroutines.
	*/

	var counter uint64 //  always-positive
	var wg sync.WaitGroup

	// We’ll start 50 goroutines that each increment the counter exactly 1000 times.
	for i := 0; i < 50; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			/*
				To atomically increment the counter we use AddUint64,
				giving it the memory address of our 'counter' with the '&' syntax.
			*/
			for j := 0; j < 1000; j++ {
				// add +1 to the counter atomically
				atomic.AddUint64(&counter, 1)
			}
		}()
	}

	wg.Wait()

	// we expected counter=50,000
	fmt.Println("We have now", counter, "operations")

	/*
		It’s safe to access 'counter' now because we know no other goroutine is writing to it.
		 Reading atomics safely while they are being updated is also possible
		 using functions like 'atomic.LoadUint64'.

		 NOTE:
		 We expect to get exactly 50,000 operations.
		 Had we used the non-atomic ops++ to increment the counter,
		 we’d likely get a different number, changing between runs,
		 because the goroutines would interfere with each other.
		 Moreover, we’d get data race failures when running with the -race flag.
	*/
}

// --------------------------- //
func example11() {
	// alibaba is our container :p
	// we don't need to fill the 'mu' mutex here
	alibaba := container{
		counters: map[string]int{"a": 0, "b": 0},
	}
	var wg sync.WaitGroup

	// This function increments a named counter in a loop.
	counting := func(name string, max int) {
		defer wg.Done()
		for i := 0; i < max; i++ {
			alibaba.increment(name)
		}
	}

	/*
		Run several goroutines concurrently;
		note that they all access the same 'container',
		and two of them access the same 'counter'.
	*/
	wg.Add(3)
	go counting("a", 1000)
	go counting("b", 1000)
	go counting("a", 1000)
	wg.Wait()

	// map[a:2000 b:1000]
	fmt.Println("Alibaba counters:", alibaba.counters)
}

type container struct {
	counters map[string]int // map, every name has a counter
	mu       sync.Mutex     // mutex to organize the go routines access
}

func (this *container) increment(name string) {
	// lock the go routines, just 1 at time
	this.mu.Lock()
	this.counters[name]++  // now we have like the atomic counter, thanks to mutex!
	defer this.mu.Unlock() // finally, it's the others go routines turn :p

	/*
		if we don't use mutex we get:
		"fatal error: concurrent map writes"
	*/
}

// --------------------------- //
func example12() {
	names := []string{"zakaria", "mona", "ilyas", "ayoub"}
	numbers := []int{8, 5, 2, 6, 3, 7, 1}

	/*
		everythings in Go are bassed by value by default
		the slices also passed by value, BUT it points to the original array
		so, yes it create a copy but it refers to the same array!

		A slice is a descriptor of an array segment:
		[ptr *array, len int, cap int]
	*/
	sort.Strings(names) // attention!
	sort.Ints(numbers)  // attention!

	fmt.Println("my names are sorted now:", names)
	fmt.Println("my numbers are sorted now:", numbers)

	isSorted := sort.StringsAreSorted(names) // check if our 'names' are sorted

	fmt.Println("is our names sorted?", isSorted)

}
